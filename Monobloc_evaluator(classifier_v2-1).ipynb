{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBefore using this notebook :\\n\\nYou should have a valid.json created during the training session. This is the one we will use.\\n\\nGoal of this notebook : \\nEvaluate our model (stocked in ../monoblocModels) with classified images. \\nWe don't care about a monobloc chair not tagged while another one is tagged in the same image,\\nwe care about images that contain one or several monobloc chair not tagged\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Before using this notebook :\n",
    "\n",
    "You should have a valid.json created during the training session. This is the one we will use.\n",
    "\n",
    "Goal of this notebook : \n",
    "Evaluate our model (stocked in ../monoblocModels) with classified images. \n",
    "We don't care about a monobloc chair not tagged while another one is tagged in the same image,\n",
    "we care about images that contain one or several monobloc chair not tagged\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monobloc_label_map.pbtxt\n",
      "../monoblocModels/v2-1/frozen_inference_graph.pb\n"
     ]
    }
   ],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = '../monoblocModels/v2-1/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'monobloc_label_map.pbtxt'\n",
    "\n",
    "#json that our model will need to import validation data\n",
    "PATH_TO_VALID = \"data/valid.json\"\n",
    "\n",
    "print(PATH_TO_LABELS)\n",
    "print(PATH_TO_CKPT)\n",
    "print(PATH_TO_VALID)\n",
    "\n",
    "\n",
    "NUM_CLASSES = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "  name: \"monobloc chair\"\n",
      "  id: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updt(total, progress, info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Show how a loop progress\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    total : int \n",
    "    maximum of the loop\n",
    "    \n",
    "    progress : int \n",
    "    the iterator\n",
    "    \n",
    "    info : string\n",
    "    name of the loading bar\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a loading bar\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    progress=progress+1\n",
    "    barLength, status = 20, \"\"\n",
    "    progress = float(progress) / float(total)\n",
    "    if progress >= 1.:\n",
    "        progress, status = 1, \"\\r\\n\"\n",
    "    block = int(round(barLength * progress))\n",
    "    text = \"\\r[{}] {:.0f}%, filename {}\".format(\n",
    "        \"#\" * block + \"-\" * (barLength - block), round(progress * 100, 0),\n",
    "        status)\n",
    "    sys.stdout.write(text + info)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    if (im_width*im_height,3)==np.array(image.getdata()).shape:\n",
    "        return np.array(image.getdata()).reshape(\n",
    "          (im_height, im_width, 3)).astype(np.uint8)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(boxes):\n",
    "    #Change a list of list of coordinates into a list of bbox dictionnaries\n",
    "    assert boxes!=[]\n",
    "    list_dict=[]\n",
    "    \n",
    "\n",
    "    for box in boxes:\n",
    "        assert box[0]<box[2]\n",
    "        assert box[1]<box[3]\n",
    "        n_dict = {'x1':box[0],'x2':box[2],'y1':box[1],'y2':box[3]}\n",
    "        list_dict.append(n_dict)\n",
    "\n",
    "    return list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_error(filenames):\n",
    "    #Function to call if load_image_into_numpy_array doesn't work\n",
    "    for path in filenames:\n",
    "        print(\"Reshape error with the file {}, it will be ignored\".format(path))\n",
    "\n",
    "        i=f_gt.index(path)\n",
    "        f_gt.remove(path)\n",
    "        del tags[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_json(path,limit=7990272):\n",
    "    \n",
    "    \"\"\"\n",
    "    Import filenames and tags from path \n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : string\n",
    "    Path to valid.json\n",
    "    \n",
    "    limit : int\n",
    "    It's the maximum number of pixels that an image should have. It's optional, in order to make this step faster and/or\n",
    "    prevent your computer from a lack of GPU to run it\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filenames : String list\n",
    "    List of image path we want to import\n",
    "    \n",
    "    tags : List of list of string\n",
    "    Tell us if an image contains monobloc chair\n",
    "    \"\"\"\n",
    "    \n",
    "    filenames=[]\n",
    "    tags=[]\n",
    "    with open(path, 'r') as f:\n",
    "        jload = json.load(f)\n",
    "        \n",
    "    for temp,data in enumerate(jload):\n",
    "        \n",
    "        seq=(\"data\", data[\"filename\"])\n",
    "        img_path=\"/\".join(seq)\n",
    "        updt(len(jload),temp,img_path)\n",
    "            \n",
    "        if(data[\"height\"]*data[\"width\"]<=limit):\n",
    "            filenames.append(img_path)\n",
    "            tags.append(data[\"tags\"])\n",
    "            \n",
    "        else :\n",
    "            print(\"\\n {} is too big, this image will be ignored\".format(img_path))\n",
    "         \n",
    "            \n",
    "            \n",
    "    return filenames, tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction afin de stocker les prédictions\n",
    "\n",
    "def save_boxes_and_scores(image_paths, threshold=0.1):\n",
    "    \n",
    "    \"\"\"\n",
    "    make predictions of every images and return them \n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_paths : List of strings\n",
    "    Path to images\n",
    "    \n",
    "    threshold : float between 0 and 1\n",
    "    The minimum score limit. We keep every bounding box with a score higher than the threshold\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_filenames : String list\n",
    "    List of image path we predicted\n",
    "    \n",
    "    list_boxes : List of list of dictionnaries\n",
    "    List of Bounding boxes predicted per images, stocked in dictionnaries this way:\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    \n",
    "    list_scores : List of list of float\n",
    "    List of each prediction's scores per images\n",
    "    \"\"\"\n",
    "    \n",
    "    list_filenames=[]\n",
    "    list_scores=[]\n",
    "    list_boxes=[]\n",
    "    error_file=[]\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "            # Definite input and output Tensors for detection_graph\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            \n",
    "            \n",
    "            for temp,image_path in enumerate(image_paths):\n",
    "                updt(len(image_paths),temp,image_path)\n",
    "                image = Image.open(image_path)\n",
    "                # the array based representation of the image will be used later in order to prepare the\n",
    "                # result image with boxes and labels on it.\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "                if len(image_np)==0:\n",
    "                    error_file.append(image_path)\n",
    "                    continue\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                # Actual detection.\n",
    "                (boxes, scores, labels, num) = sess.run([detection_boxes, \n",
    "                                                          detection_scores, \n",
    "                                                          detection_classes, \n",
    "                                                          num_detections],feed_dict={image_tensor: image_np_expanded})\n",
    "                #scores =[ [score classe 0] [score classe 1 ] etc... ]\n",
    "                #boxes = [[bbox1] [bbox2] etc...]\n",
    "                \n",
    "                #On stocke la prédiction selon le seuil choisi dans s et b\n",
    "                s=[]\n",
    "                b=[]\n",
    "                d={}\n",
    "                for i in range (len(scores[0])): \n",
    "                    if (scores[0][i]>=threshold):\n",
    "                        s.append(scores[0][i])\n",
    "                        b.append(boxes[0][i]) #Format [left, top, right, bottom] NORMALIZED \n",
    "                if (b==[]):\n",
    "                    d=[{}]\n",
    "                else :\n",
    "                    d=make_dict(b)\n",
    "                list_scores.append(s.copy())\n",
    "                list_boxes.append(d.copy())\n",
    "                list_filenames.append(image_path)\n",
    "                \n",
    "            reshape_error(error_file)\n",
    "\n",
    "                \n",
    "    return list_filenames, list_scores, list_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[###-----------------] 17%, filename data/Images+json/img/monobloc (76).jpggf6e8.jpg\n",
      " data/Images+json/img/monobloc (76).jpg is too big, this image will be ignored\n",
      "[##########----------] 52%, filename data/Images+json/img/monobloc (74).jpg5935b.jpg\n",
      " data/Images+json/img/monobloc (74).jpg is too big, this image will be ignored\n",
      "[####################] 100%, filename data/Images+json/img/000000041495.jpggc18b.jpg\n",
      "[--------------------] 0%, filename data/Images+json/img/monobloc (124).jpg"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Images+json/img/monobloc (124).jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-921c65541b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/data.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7990272\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_boxes_and_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_gt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-a7008a0f4868>\u001b[0m in \u001b[0;36msave_boxes_and_scores\u001b[0;34m(image_paths, threshold)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mupdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# the array based representation of the image will be used later in order to prepare the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# result image with boxes and labels on it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2580\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2581\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Images+json/img/monobloc (124).jpg'"
     ]
    }
   ],
   "source": [
    "global f_gt\n",
    "global tags\n",
    "\n",
    "f_gt, tags = import_json(PATH_TO_VALID,7990272)\n",
    "filenames, scores, boxes = save_boxes_and_scores(f_gt,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_classifier(tags):\n",
    "    \n",
    "    \"\"\"\n",
    "    Just to know how many positive images are present in the validation set:\n",
    "    \"\"\"\n",
    "    \n",
    "    imgpos=0\n",
    "    imgneg=0\n",
    "\n",
    "    for i in range (len(tags)):\n",
    "        if tags[i]==[]:\n",
    "            imgneg+=1\n",
    "        else:\n",
    "            imgpos+=1\n",
    "    print(\" The validation dataset contains {} positive images and {} negative images \\n\".format(imgpos, imgneg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_posneg(filenames,scores,boxes,tags):\n",
    "    \n",
    "    \"\"\"\n",
    "    calculate the number of True Positive, True Negative, False Positive and False Negative images\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filenames : List of string\n",
    "    List of every image path contained in the validation set\n",
    "    \n",
    "    scores : List of list of float\n",
    "    List of list of predicted scores\n",
    "    \n",
    "    boxes : List of list of dictionnaries\n",
    "    List of list of Bounding boxes predicted, stocked in dictionnaries this way:\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "        \n",
    "    tags : List of tags\n",
    "    List of groundtruth tags\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tp : int\n",
    "    number of true positive boxes (boxes well predicted)\n",
    "    \n",
    "    fn : int\n",
    "    number of false negative boxes (the researched object is present, but not found by the model)\n",
    "    \n",
    "    fp : int\n",
    "    number of false positive boxes (object detected where there is nothing interesting)\n",
    "    \n",
    "    tn : int\n",
    "    number of true negative boxes (no boxes predicted where there is no monobloc chair)\n",
    "    \n",
    "    error_path : list of string\n",
    "    list of path where our model failed to predict\n",
    "    \n",
    "    error_reason : list of string\n",
    "    list of string. strings are \"false positive\" or \"false negative\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert threshold<=1\n",
    "    assert threshold>=0\n",
    "     \n",
    "    #boxes2 = b_gt and threshold is the value that determine know if the model identified a monobloc\n",
    "    tp, fn, fp, tn = 0, 0, 0, 0\n",
    "    error_path=[]\n",
    "    error_reason=[]\n",
    "    \n",
    "    for i in range (len(filenames)):\n",
    "        \n",
    "        if (scores[i]==[]):\n",
    "            if tags[i]==[]:\n",
    "                tn+=1\n",
    "            \n",
    "            else:\n",
    "                fn+=1\n",
    "                error_reason.append(\"False negative image\")\n",
    "                error_path.append(filenames[i])\n",
    "            \n",
    "        else:\n",
    "            if (scores[i][0]>threshold):\n",
    "                if tags[i]!=[]:\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    fp+=1\n",
    "                    error_reason.append(\"False positive image\")\n",
    "                    error_path.append(filenames[i])\n",
    "            else :\n",
    "                if tags[i]==[]:\n",
    "                    tn+=1\n",
    "                else:\n",
    "                    fn+=1\n",
    "                    error_reason.append(\"False negative image\")\n",
    "                    error_path.append(filenames[i])\n",
    "                \n",
    "    \n",
    "    return tp, fn, fp, tn, error_path, error_reason\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred(image_paths,titles, IMAGE_SIZE=(12, 8)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Print with predicted bounding boxes, images where our model failed to predict correctly\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_paths : List of string\n",
    "    List of path where our model failed the prediction\n",
    "    \n",
    "    titles : List of string\n",
    "    List of reason of prediction failure\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "            # Definite input and output Tensors for detection_graph\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            \n",
    "            temp=0\n",
    "            for image_path, title in zip(image_paths, titles):\n",
    "                updt(len(image_paths),temp,image_path)\n",
    "                image = Image.open(image_path)\n",
    "                # the array based representation of the image will be used later in order to prepare the\n",
    "                # result image with boxes and labels on it.\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num) = sess.run([detection_boxes, \n",
    "                                                          detection_scores, \n",
    "                                                          detection_classes, \n",
    "                                                          num_detections],feed_dict={image_tensor: image_np_expanded})\n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(image_np,\n",
    "                                                                   np.squeeze(boxes),\n",
    "                                                                   np.squeeze(classes).astype(np.int32),\n",
    "                                                                   np.squeeze(scores),\n",
    "                                                                   category_index,\n",
    "                                                                   min_score_thresh=.2,\n",
    "                                                                   use_normalized_coordinates=True,\n",
    "                                                                   line_thickness=3)\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.title(title)\n",
    "                plt.imshow(image_np)\n",
    "                temp+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To print the confusion matrix \n",
    "threshold=0.8\n",
    "img_classifier(tags) \n",
    "tp, fn, fp, tn, error_path, error_reason = img_posneg(filenames,scores,boxes,tags,threshold)\n",
    "print_pred(error_path,error_reason)\n",
    "\n",
    "print(\"\\n Confusion Matrix about 'Is there at least one monobloc in this image?' with threshold score>{} : \\n Percentage of True Positive : {}% \\n Percentage of False Positive : {}% \\n Percentage of True Negative : {}% \\n Percentage of False Negative : {}%\".format(threshold,tp/(tp+fn+fp+tn)*100,fp/(tp+fn+fp+tn)*100,tn/(tp+fn+fp+tn)*100,fn/(tp+fn+fp+tn)*100))\n",
    "print(\"Which means that {} images well predicted against {} miss predicted\".format(tp+tn,fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_graph(filenames,scores,boxes,tags):\n",
    "    \n",
    "    \"\"\"\n",
    "    Print false neg and false pos curves switchin several score threshold\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filenames : List of string\n",
    "    List of every image path contained in the validation set\n",
    "    \n",
    "    scores : List of list of float\n",
    "    List of list of predicted scores\n",
    "    \n",
    "    boxes : List of list of dictionnaries\n",
    "    List of list of Bounding boxes predicted, stocked in dictionnaries this way:\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "        \n",
    "    tags : List of tags\n",
    "    List of groundtruth tags\n",
    "    \"\"\"\n",
    "    \n",
    "    thresholds=np.arange(0.1,1,0.05)\n",
    "    list_fn=[]\n",
    "    list_fp=[]\n",
    "    both=[]\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        tp, fn, fp, tn, caca, prout = img_posneg(filenames,scores,boxes,tags,threshold)\n",
    "        list_fn.append(fn/len(filenames))\n",
    "        list_fp.append(fp/len(filenames))\n",
    "        both.append((fp+fn)/len(filenames))\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.title(\"false positive(-.), false negative(--) and sum(line) curves according to several score thresholds\")\n",
    "    plt.xlabel(\"minimum score thresholds\")\n",
    "    plt.ylabel(\"number of false images in percent\")\n",
    "    plt.plot(thresholds, list_fn,'r--', thresholds, list_fp,'b-.', thresholds, both, 'g')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_graph(filenames,scores,boxes,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
